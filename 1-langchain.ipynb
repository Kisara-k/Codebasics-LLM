{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nimport os\n\nuser_secrets = UserSecretsClient()\nos.environ['OPENAI_API_KEY'] = user_secrets.get_secret(\"openai_api_key\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T05:09:47.612213Z","iopub.execute_input":"2025-01-20T05:09:47.612552Z","iopub.status.idle":"2025-01-20T05:09:47.788686Z","shell.execute_reply.started":"2025-01-20T05:09:47.612529Z","shell.execute_reply":"2025-01-20T05:09:47.787528Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# !pip install langchain\n!pip install langchain_community\n# !pip install openai\n!pip install -U langchain-openai","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T05:10:11.385314Z","iopub.execute_input":"2025-01-20T05:10:11.385707Z","iopub.status.idle":"2025-01-20T05:10:21.742763Z","shell.execute_reply.started":"2025-01-20T05:10:11.385669Z","shell.execute_reply":"2025-01-20T05:10:21.741464Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.3.14)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.36)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.11.10)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\nRequirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.4.0)\nRequirement already satisfied: langchain<0.4.0,>=0.3.14 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.3.14)\nRequirement already satisfied: langchain-core<0.4.0,>=0.3.29 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.3.30)\nRequirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.3)\nRequirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\nRequirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.7.1)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (9.0.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.24.2)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\nRequirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.14->langchain_community) (0.3.3)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.14->langchain_community) (2.10.3)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain_community) (1.33)\nRequirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain_community) (24.2)\nRequirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain_community) (4.12.2)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain_community) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain_community) (3.10.12)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain_community) (1.0.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.22.4->langchain_community) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.22.4->langchain_community) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.22.4->langchain_community) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.22.4->langchain_community) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.22.4->langchain_community) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.22.4->langchain_community) (2.4.1)\nRequirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.12.14)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\nRequirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (3.7.1)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain_community) (3.0.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.14->langchain_community) (0.7.0)\nRequirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.14->langchain_community) (2.27.1)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2,>=1.22.4->langchain_community) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2,>=1.22.4->langchain_community) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2,>=1.22.4->langchain_community) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2,>=1.22.4->langchain_community) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2,>=1.22.4->langchain_community) (2024.2.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (1.3.1)\nRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (1.2.2)\nCollecting langchain-openai\n  Downloading langchain_openai-0.3.1-py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: langchain-core<0.4.0,>=0.3.30 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.3.30)\nCollecting openai<2.0.0,>=1.58.1 (from langchain-openai)\n  Downloading openai-1.59.8-py3-none-any.whl.metadata (27 kB)\nRequirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.8.0)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.30->langchain-openai) (6.0.2)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.30->langchain-openai) (1.33)\nRequirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.30->langchain-openai) (0.2.3)\nRequirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.30->langchain-openai) (24.2)\nRequirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.30->langchain-openai) (2.10.3)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.30->langchain-openai) (9.0.0)\nRequirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.30->langchain-openai) (4.12.2)\nRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (3.7.1)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.28.1)\nRequirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.8.2)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.3.1)\nRequirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.67.1)\nRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\nRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain-openai) (3.10)\nRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain-openai) (1.2.2)\nRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (2024.12.14)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.30->langchain-openai) (3.0.0)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.30->langchain-openai) (3.10.12)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.30->langchain-openai) (1.0.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.30->langchain-openai) (0.7.0)\nRequirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.30->langchain-openai) (2.27.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.0)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.2.3)\nDownloading langchain_openai-0.3.1-py3-none-any.whl (54 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.3/54.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading openai-1.59.8-py3-none-any.whl (455 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m455.6/455.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: openai, langchain-openai\n  Attempting uninstall: openai\n    Found existing installation: openai 1.57.4\n    Uninstalling openai-1.57.4:\n      Successfully uninstalled openai-1.57.4\nSuccessfully installed langchain-openai-0.3.1 openai-1.59.8\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\", module=\"langchain\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T06:05:47.771544Z","iopub.execute_input":"2025-01-20T06:05:47.771899Z","iopub.status.idle":"2025-01-20T06:05:47.776744Z","shell.execute_reply.started":"2025-01-20T06:05:47.771872Z","shell.execute_reply":"2025-01-20T06:05:47.775318Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"# from langchain.llms import OpenAI\nfrom langchain_openai import OpenAI\n\nllm = OpenAI(temperature=0.7)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T05:10:32.008223Z","iopub.execute_input":"2025-01-20T05:10:32.008567Z","iopub.status.idle":"2025-01-20T05:10:32.890835Z","shell.execute_reply.started":"2025-01-20T05:10:32.008541Z","shell.execute_reply":"2025-01-20T05:10:32.889999Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def printf(data, col=4):\n    col_width = max(len(str(x)) for x in data)\n    for i, x in enumerate(data, 1):\n        print(f\"{x:<{col_width}}\", end=\"\\n\" if i % col == 0 else \"\")\n\ndef printt(tuples):\n    for tuple_ in tuples:\n        print(tuple_[0])\n        print(tuple_[1])\n        print()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T06:11:39.964427Z","iopub.execute_input":"2025-01-20T06:11:39.964780Z","iopub.status.idle":"2025-01-20T06:11:39.970803Z","shell.execute_reply.started":"2025-01-20T06:11:39.964753Z","shell.execute_reply":"2025-01-20T06:11:39.969789Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":76},{"cell_type":"code","source":"# Print all the attributes of llm object\nprintt([(i, getattr(llm, i)) for i in dir(llm) if not i.startswith(\"_\")])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T03:47:00.975231Z","iopub.execute_input":"2025-01-20T03:47:00.975778Z","iopub.status.idle":"2025-01-20T03:47:01.042991Z","shell.execute_reply.started":"2025-01-20T03:47:00.975706Z","shell.execute_reply":"2025-01-20T03:47:01.041608Z"},"scrolled":true,"collapsed":true,"jupyter":{"outputs_hidden":true},"_kg_hide-input":false},"outputs":[{"name":"stdout","text":"InputType\ntyping.Union[str, langchain_core.prompt_values.StringPromptValue, langchain_core.prompt_values.ChatPromptValueConcrete, list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x7adb359c71c0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]]\n\nOutputType\n<class 'str'>\n\nabatch\n<bound method BaseLLM.abatch of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\nabatch_as_completed\n<bound method Runnable.abatch_as_completed of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\nagenerate\n<bound method BaseLLM.agenerate of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\nagenerate_prompt\n<bound method BaseLLM.agenerate_prompt of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\nainvoke\n<bound method BaseLLM.ainvoke of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\nallowed_special\nset()\n\napredict\n<bound method BaseLLM.apredict of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\napredict_messages\n<bound method BaseLLM.apredict_messages of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\nas_tool\n<bound method Runnable.as_tool of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\nassign\n<bound method Runnable.assign of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\nastream\n<bound method BaseLLM.astream of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\nastream_events\n<bound method Runnable.astream_events of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\nastream_log\n<bound method Runnable.astream_log of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\nasync_client\n<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>\n\natransform\n<bound method Runnable.atransform of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\nbatch\n<bound method BaseLLM.batch of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\nbatch_as_completed\n<bound method Runnable.batch_as_completed of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\nbatch_size\n20\n\nbest_of\n1\n\nbind\n<bound method Runnable.bind of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\nbuild_extra\n<bound method BaseOpenAI.build_extra of <class 'langchain_openai.llms.base.OpenAI'>>\n\ncache\nNone\n\ncallback_manager\nNone\n\ncallbacks\nNone\n\nclient\n<openai.resources.completions.Completions object at 0x7adb348a1030>\n\nconfig_schema\n<bound method Runnable.config_schema of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\nconfig_specs\n[]\n\nconfigurable_alternatives\n<bound method RunnableSerializable.configurable_alternatives of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\nconfigurable_fields\n<bound method RunnableSerializable.configurable_fields of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\nconstruct\n<bound method BaseModel.construct of <class 'langchain_openai.llms.base.OpenAI'>>\n\ncopy\n<bound method BaseModel.copy of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\ncreate_llm_result\n<bound method BaseOpenAI.create_llm_result of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\ncustom_get_token_ids\nNone\n\ndefault_headers\nNone\n\ndefault_query\nNone\n\ndict\n<bound method BaseLLM.dict of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\ndisallowed_special\nall\n\nextra_body\nNone\n\nfrequency_penalty\n0\n\nfrom_orm\n<bound method BaseModel.from_orm of <class 'langchain_openai.llms.base.OpenAI'>>\n\ngenerate\n<bound method BaseLLM.generate of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\ngenerate_prompt\n<bound method BaseLLM.generate_prompt of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\nget_config_jsonschema\n<bound method Runnable.get_config_jsonschema of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\nget_graph\n<bound method Runnable.get_graph of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\nget_input_jsonschema\n<bound method Runnable.get_input_jsonschema of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\nget_input_schema\n<bound method Runnable.get_input_schema of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\nget_lc_namespace\n<bound method OpenAI.get_lc_namespace of <class 'langchain_openai.llms.base.OpenAI'>>\n\nget_name\n<bound method Runnable.get_name of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\nget_num_tokens\n<bound method BaseLanguageModel.get_num_tokens of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\nget_num_tokens_from_messages\n<bound method BaseLanguageModel.get_num_tokens_from_messages of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\nget_output_jsonschema\n<bound method Runnable.get_output_jsonschema of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\nget_output_schema\n<bound method Runnable.get_output_schema of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\nget_prompts\n<bound method Runnable.get_prompts of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\nget_sub_prompts\n<bound method BaseOpenAI.get_sub_prompts of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\nget_token_ids\n<bound method BaseOpenAI.get_token_ids of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\nhttp_async_client\nNone\n\nhttp_client\nNone\n\ninput_schema\n<class 'langchain_openai.llms.base.OpenAIInput'>\n\ninvoke\n<bound method BaseLLM.invoke of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\nis_lc_serializable\n<bound method OpenAI.is_lc_serializable of <class 'langchain_openai.llms.base.OpenAI'>>\n\njson\n<bound method BaseModel.json of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\nlc_attributes\n{}\n\nlc_id\n<bound method Serializable.lc_id of <class 'langchain_openai.llms.base.OpenAI'>>\n\nlc_secrets\n{'openai_api_key': 'OPENAI_API_KEY'}\n\nlogit_bias\nNone\n\nlogprobs\nNone\n\nmap\n<bound method Runnable.map of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\nmax_context_size\n4096\n\nmax_retries\n2\n\nmax_tokens\n256\n\nmax_tokens_for_prompt\n<bound method BaseOpenAI.max_tokens_for_prompt of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\nmetadata\nNone\n\nmodel_computed_fields\n{}\n\nmodel_config\n{'extra': 'ignore', 'protected_namespaces': (), 'arbitrary_types_allowed': True, 'populate_by_name': True}\n\nmodel_construct\n<bound method BaseModel.model_construct of <class 'langchain_openai.llms.base.OpenAI'>>\n\nmodel_copy\n<bound method BaseModel.model_copy of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\nmodel_dump\n<bound method BaseModel.model_dump of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\nmodel_dump_json\n<bound method BaseModel.model_dump_json of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\nmodel_extra\nNone\n\nmodel_fields\n{'name': FieldInfo(annotation=Union[str, NoneType], required=False, default=None), 'cache': FieldInfo(annotation=Union[BaseCache, bool, NoneType], required=False, default=None, exclude=True), 'verbose': FieldInfo(annotation=bool, required=False, default_factory=_get_verbosity, exclude=True, repr=False), 'callbacks': FieldInfo(annotation=Union[list[BaseCallbackHandler], BaseCallbackManager, NoneType], required=False, default=None, exclude=True), 'tags': FieldInfo(annotation=Union[list[str], NoneType], required=False, default=None, exclude=True), 'metadata': FieldInfo(annotation=Union[dict[str, Any], NoneType], required=False, default=None, exclude=True), 'custom_get_token_ids': FieldInfo(annotation=Union[Callable[list, list[int]], NoneType], required=False, default=None, exclude=True), 'callback_manager': FieldInfo(annotation=Union[BaseCallbackManager, NoneType], required=False, default=None, exclude=True), 'client': FieldInfo(annotation=Any, required=False, default=None, exclude=True), 'async_client': FieldInfo(annotation=Any, required=False, default=None, exclude=True), 'model_name': FieldInfo(annotation=str, required=False, default='gpt-3.5-turbo-instruct', alias='model', alias_priority=2), 'temperature': FieldInfo(annotation=float, required=False, default=0.7), 'max_tokens': FieldInfo(annotation=int, required=False, default=256), 'top_p': FieldInfo(annotation=float, required=False, default=1), 'frequency_penalty': FieldInfo(annotation=float, required=False, default=0), 'presence_penalty': FieldInfo(annotation=float, required=False, default=0), 'n': FieldInfo(annotation=int, required=False, default=1), 'best_of': FieldInfo(annotation=int, required=False, default=1), 'model_kwargs': FieldInfo(annotation=Dict[str, Any], required=False, default_factory=dict), 'openai_api_key': FieldInfo(annotation=Union[SecretStr, NoneType], required=False, default_factory=get_secret_from_env, alias='api_key', alias_priority=2), 'openai_api_base': FieldInfo(annotation=Union[str, NoneType], required=False, default_factory=get_from_env_fn, alias='base_url', alias_priority=2), 'openai_organization': FieldInfo(annotation=Union[str, NoneType], required=False, default_factory=get_from_env_fn, alias='organization', alias_priority=2), 'openai_proxy': FieldInfo(annotation=Union[str, NoneType], required=False, default_factory=get_from_env_fn), 'batch_size': FieldInfo(annotation=int, required=False, default=20), 'request_timeout': FieldInfo(annotation=Union[float, Tuple[float, float], Any, NoneType], required=False, default=None, alias='timeout', alias_priority=2), 'logit_bias': FieldInfo(annotation=Union[Dict[str, float], NoneType], required=False, default=None), 'max_retries': FieldInfo(annotation=int, required=False, default=2), 'seed': FieldInfo(annotation=Union[int, NoneType], required=False, default=None), 'logprobs': FieldInfo(annotation=Union[int, NoneType], required=False, default=None), 'streaming': FieldInfo(annotation=bool, required=False, default=False), 'allowed_special': FieldInfo(annotation=Union[Literal['all'], AbstractSet[str]], required=False, default=set()), 'disallowed_special': FieldInfo(annotation=Union[Literal['all'], Collection[str]], required=False, default='all'), 'tiktoken_model_name': FieldInfo(annotation=Union[str, NoneType], required=False, default=None), 'default_headers': FieldInfo(annotation=Union[Mapping[str, str], NoneType], required=False, default=None), 'default_query': FieldInfo(annotation=Union[Mapping[str, object], NoneType], required=False, default=None), 'http_client': FieldInfo(annotation=Union[Any, NoneType], required=False, default=None), 'http_async_client': FieldInfo(annotation=Union[Any, NoneType], required=False, default=None), 'extra_body': FieldInfo(annotation=Union[Mapping[str, Any], NoneType], required=False, default=None)}\n\nmodel_fields_set\n{'model_kwargs', 'temperature', 'client', 'async_client'}\n\nmodel_json_schema\n<bound method BaseModel.model_json_schema of <class 'langchain_openai.llms.base.OpenAI'>>\n\nmodel_kwargs\n{}\n\nmodel_name\ngpt-3.5-turbo-instruct\n\nmodel_parametrized_name\n<bound method BaseModel.model_parametrized_name of <class 'langchain_openai.llms.base.OpenAI'>>\n\nmodel_post_init\n<bound method BaseModel.model_post_init of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\nmodel_rebuild\n<bound method BaseModel.model_rebuild of <class 'langchain_openai.llms.base.OpenAI'>>\n\nmodel_validate\n<bound method BaseModel.model_validate of <class 'langchain_openai.llms.base.OpenAI'>>\n\nmodel_validate_json\n<bound method BaseModel.model_validate_json of <class 'langchain_openai.llms.base.OpenAI'>>\n\nmodel_validate_strings\n<bound method BaseModel.model_validate_strings of <class 'langchain_openai.llms.base.OpenAI'>>\n\nmodelname_to_contextsize\n<function BaseOpenAI.modelname_to_contextsize at 0x7adb327f8b80>\n\nn\n1\n\nname\nNone\n\nopenai_api_base\nNone\n\nopenai_api_key\n**********\n\nopenai_organization\nNone\n\nopenai_proxy\nNone\n\noutput_schema\n<class 'langchain_openai.llms.base.OpenAIOutput'>\n\nparse_file\n<bound method BaseModel.parse_file of <class 'langchain_openai.llms.base.OpenAI'>>\n\nparse_obj\n<bound method BaseModel.parse_obj of <class 'langchain_openai.llms.base.OpenAI'>>\n\nparse_raw\n<bound method BaseModel.parse_raw of <class 'langchain_openai.llms.base.OpenAI'>>\n\npick\n<bound method Runnable.pick of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\npipe\n<bound method Runnable.pipe of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\npredict\n<bound method BaseLLM.predict of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\npredict_messages\n<bound method BaseLLM.predict_messages of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\npresence_penalty\n0\n\nraise_deprecation\n<bound method BaseLLM.raise_deprecation of <class 'langchain_openai.llms.base.OpenAI'>>\n\nrequest_timeout\nNone\n\nsave\n<bound method BaseLLM.save of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\nschema\n<bound method BaseModel.schema of <class 'langchain_openai.llms.base.OpenAI'>>\n\nschema_json\n<bound method BaseModel.schema_json of <class 'langchain_openai.llms.base.OpenAI'>>\n\nseed\nNone\n\nset_verbose\n<bound method BaseLanguageModel.set_verbose of <class 'langchain_openai.llms.base.OpenAI'>>\n\nstream\n<bound method BaseLLM.stream of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\nstreaming\nFalse\n\ntags\nNone\n\ntemperature\n0.7\n\ntiktoken_model_name\nNone\n\nto_json\n<bound method RunnableSerializable.to_json of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\nto_json_not_implemented\n<bound method Serializable.to_json_not_implemented of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\ntop_p\n1\n\ntransform\n<bound method Runnable.transform of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\nupdate_forward_refs\n<bound method BaseModel.update_forward_refs of <class 'langchain_openai.llms.base.OpenAI'>>\n\nvalidate\n<bound method BaseModel.validate of <class 'langchain_openai.llms.base.OpenAI'>>\n\nvalidate_environment\n<bound method BaseOpenAI.validate_environment of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\nverbose\nFalse\n\nwith_alisteners\n<bound method Runnable.with_alisteners of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\nwith_config\n<bound method Runnable.with_config of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\nwith_fallbacks\n<bound method Runnable.with_fallbacks of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\nwith_listeners\n<bound method Runnable.with_listeners of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\nwith_retry\n<bound method Runnable.with_retry of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\nwith_structured_output\n<bound method BaseLanguageModel.with_structured_output of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\nwith_types\n<bound method Runnable.with_types of OpenAI(client=<openai.resources.completions.Completions object at 0x7adb348a1030>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7adb3441d660>, model_kwargs={}, openai_api_key=SecretStr('**********'))>\n\n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":"printf(dir(llm))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T03:41:41.110333Z","iopub.execute_input":"2025-01-20T03:41:41.110763Z","iopub.status.idle":"2025-01-20T03:41:41.159771Z","shell.execute_reply.started":"2025-01-20T03:41:41.110704Z","shell.execute_reply":"2025-01-20T03:41:41.158630Z"},"scrolled":true,"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"InputType                     OutputType                    __abstractmethods__           __annotations__               \n__call__                      __class__                     __class_getitem__             __class_vars__                \n__copy__                      __deepcopy__                  __delattr__                   __dict__                      \n__dir__                       __doc__                       __eq__                        __fields__                    \n__fields_set__                __format__                    __ge__                        __get_pydantic_core_schema__  \n__get_pydantic_json_schema__  __getattr__                   __getattribute__              __getstate__                  \n__gt__                        __hash__                      __init__                      __init_subclass__             \n__iter__                      __le__                        __lt__                        __module__                    \n__ne__                        __new__                       __or__                        __orig_bases__                \n__parameters__                __pretty__                    __private_attributes__        __pydantic_complete__         \n__pydantic_computed_fields__  __pydantic_core_schema__      __pydantic_custom_init__      __pydantic_decorators__       \n__pydantic_extra__            __pydantic_fields__           __pydantic_fields_set__       __pydantic_generic_metadata__ \n__pydantic_init_subclass__    __pydantic_parent_namespace__ __pydantic_post_init__        __pydantic_private__          \n__pydantic_root_model__       __pydantic_serializer__       __pydantic_validator__        __reduce__                    \n__reduce_ex__                 __replace__                   __repr__                      __repr_args__                 \n__repr_name__                 __repr_recursion__            __repr_str__                  __rich_repr__                 \n__ror__                       __setattr__                   __setstate__                  __signature__                 \n__sizeof__                    __slots__                     __str__                       __subclasshook__              \n__weakref__                   _abatch_with_config           _abc_impl                     _acall_with_config            \n_agenerate                    _agenerate_helper             _all_required_field_names     _astream                      \n_atransform_stream_with_config_batch_with_config            _calculate_keys               _call_async                   \n_call_with_config             _check_frozen                 _convert_input                _copy_and_set_values          \n_default_params               _generate                     _generate_helper              _get_ls_params                \n_get_run_ids_list             _get_value                    _identifying_params           _invocation_params            \n_is_protocol                  _iter                         _llm_type                     _serialized                   \n_stream                       _transform_stream_with_config abatch                        abatch_as_completed           \nagenerate                     agenerate_prompt              ainvoke                       allowed_special               \napredict                      apredict_messages             as_tool                       assign                        \nastream                       astream_events                astream_log                   async_client                  \natransform                    batch                         batch_as_completed            batch_size                    \nbest_of                       bind                          build_extra                   cache                         \ncallback_manager              callbacks                     client                        config_schema                 \nconfig_specs                  configurable_alternatives     configurable_fields           construct                     \ncopy                          create_llm_result             custom_get_token_ids          default_headers               \ndefault_query                 dict                          disallowed_special            extra_body                    \nfrequency_penalty             from_orm                      generate                      generate_prompt               \nget_config_jsonschema         get_graph                     get_input_jsonschema          get_input_schema              \nget_lc_namespace              get_name                      get_num_tokens                get_num_tokens_from_messages  \nget_output_jsonschema         get_output_schema             get_prompts                   get_sub_prompts               \nget_token_ids                 http_async_client             http_client                   input_schema                  \ninvoke                        is_lc_serializable            json                          lc_attributes                 \nlc_id                         lc_secrets                    logit_bias                    logprobs                      \nmap                           max_context_size              max_retries                   max_tokens                    \nmax_tokens_for_prompt         metadata                      model_computed_fields         model_config                  \nmodel_construct               model_copy                    model_dump                    model_dump_json               \nmodel_extra                   model_fields                  model_fields_set              model_json_schema             \nmodel_kwargs                  model_name                    model_parametrized_name       model_post_init               \nmodel_rebuild                 model_validate                model_validate_json           model_validate_strings        \nmodelname_to_contextsize      n                             name                          openai_api_base               \nopenai_api_key                openai_organization           openai_proxy                  output_schema                 \nparse_file                    parse_obj                     parse_raw                     pick                          \npipe                          predict                       predict_messages              presence_penalty              \nraise_deprecation             request_timeout               save                          schema                        \nschema_json                   seed                          set_verbose                   stream                        \nstreaming                     tags                          temperature                   tiktoken_model_name           \nto_json                       to_json_not_implemented       top_p                         transform                     \nupdate_forward_refs           validate                      validate_environment          verbose                       \nwith_alisteners               with_config                   with_fallbacks                with_listeners                \nwith_retry                    with_structured_output        with_types                    ","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"llm.model_fields","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T03:42:25.490900Z","iopub.execute_input":"2025-01-20T03:42:25.491239Z","iopub.status.idle":"2025-01-20T03:42:25.500357Z","shell.execute_reply.started":"2025-01-20T03:42:25.491212Z","shell.execute_reply":"2025-01-20T03:42:25.499047Z"},"scrolled":true,"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"{'name': FieldInfo(annotation=Union[str, NoneType], required=False, default=None),\n 'cache': FieldInfo(annotation=Union[BaseCache, bool, NoneType], required=False, default=None, exclude=True),\n 'verbose': FieldInfo(annotation=bool, required=False, default_factory=_get_verbosity, exclude=True, repr=False),\n 'callbacks': FieldInfo(annotation=Union[list[BaseCallbackHandler], BaseCallbackManager, NoneType], required=False, default=None, exclude=True),\n 'tags': FieldInfo(annotation=Union[list[str], NoneType], required=False, default=None, exclude=True),\n 'metadata': FieldInfo(annotation=Union[dict[str, Any], NoneType], required=False, default=None, exclude=True),\n 'custom_get_token_ids': FieldInfo(annotation=Union[Callable[list, list[int]], NoneType], required=False, default=None, exclude=True),\n 'callback_manager': FieldInfo(annotation=Union[BaseCallbackManager, NoneType], required=False, default=None, exclude=True),\n 'client': FieldInfo(annotation=Any, required=False, default=None, exclude=True),\n 'async_client': FieldInfo(annotation=Any, required=False, default=None, exclude=True),\n 'model_name': FieldInfo(annotation=str, required=False, default='gpt-3.5-turbo-instruct', alias='model', alias_priority=2),\n 'temperature': FieldInfo(annotation=float, required=False, default=0.7),\n 'max_tokens': FieldInfo(annotation=int, required=False, default=256),\n 'top_p': FieldInfo(annotation=float, required=False, default=1),\n 'frequency_penalty': FieldInfo(annotation=float, required=False, default=0),\n 'presence_penalty': FieldInfo(annotation=float, required=False, default=0),\n 'n': FieldInfo(annotation=int, required=False, default=1),\n 'best_of': FieldInfo(annotation=int, required=False, default=1),\n 'model_kwargs': FieldInfo(annotation=Dict[str, Any], required=False, default_factory=dict),\n 'openai_api_key': FieldInfo(annotation=Union[SecretStr, NoneType], required=False, default_factory=get_secret_from_env, alias='api_key', alias_priority=2),\n 'openai_api_base': FieldInfo(annotation=Union[str, NoneType], required=False, default_factory=get_from_env_fn, alias='base_url', alias_priority=2),\n 'openai_organization': FieldInfo(annotation=Union[str, NoneType], required=False, default_factory=get_from_env_fn, alias='organization', alias_priority=2),\n 'openai_proxy': FieldInfo(annotation=Union[str, NoneType], required=False, default_factory=get_from_env_fn),\n 'batch_size': FieldInfo(annotation=int, required=False, default=20),\n 'request_timeout': FieldInfo(annotation=Union[float, Tuple[float, float], Any, NoneType], required=False, default=None, alias='timeout', alias_priority=2),\n 'logit_bias': FieldInfo(annotation=Union[Dict[str, float], NoneType], required=False, default=None),\n 'max_retries': FieldInfo(annotation=int, required=False, default=2),\n 'seed': FieldInfo(annotation=Union[int, NoneType], required=False, default=None),\n 'logprobs': FieldInfo(annotation=Union[int, NoneType], required=False, default=None),\n 'streaming': FieldInfo(annotation=bool, required=False, default=False),\n 'allowed_special': FieldInfo(annotation=Union[Literal['all'], AbstractSet[str]], required=False, default=set()),\n 'disallowed_special': FieldInfo(annotation=Union[Literal['all'], Collection[str]], required=False, default='all'),\n 'tiktoken_model_name': FieldInfo(annotation=Union[str, NoneType], required=False, default=None),\n 'default_headers': FieldInfo(annotation=Union[Mapping[str, str], NoneType], required=False, default=None),\n 'default_query': FieldInfo(annotation=Union[Mapping[str, object], NoneType], required=False, default=None),\n 'http_client': FieldInfo(annotation=Union[Any, NoneType], required=False, default=None),\n 'http_async_client': FieldInfo(annotation=Union[Any, NoneType], required=False, default=None),\n 'extra_body': FieldInfo(annotation=Union[Mapping[str, Any], NoneType], required=False, default=None)}"},"metadata":{}}],"execution_count":51},{"cell_type":"markdown","source":"# Langchain","metadata":{}},{"cell_type":"code","source":"print(llm(\"What is langchain?\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T03:47:20.754901Z","iopub.execute_input":"2025-01-20T03:47:20.755302Z","iopub.status.idle":"2025-01-20T03:47:22.507828Z","shell.execute_reply.started":"2025-01-20T03:47:20.755275Z","shell.execute_reply":"2025-01-20T03:47:22.506804Z"}},"outputs":[{"name":"stdout","text":"\n\nLangchain is a term that is often used in the field of linguistics to refer to a network of interconnected languages. This can include languages that are genetically related, as well as those that have influenced each other through contact and borrowing. The term is also sometimes used to describe the similarities and differences between languages and how they are related to each other. Langchain can also refer to the study of these language networks. \n","output_type":"stream"}],"execution_count":54},{"cell_type":"code","source":"from langchain.prompts import PromptTemplate\n\nllm = OpenAI(temperature=0.7)\n\nname_template = PromptTemplate(\n    input_variables = ['cuisine'],\n    template = 'I want to open a restaurant for {cuisine} food. Suggest a fancy name for this.'\n)\n\nname_template.format(cuisine=\"bread\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T03:52:01.630022Z","iopub.execute_input":"2025-01-20T03:52:01.630444Z","iopub.status.idle":"2025-01-20T03:52:01.638879Z","shell.execute_reply.started":"2025-01-20T03:52:01.630415Z","shell.execute_reply":"2025-01-20T03:52:01.637564Z"}},"outputs":[{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"'I want to open a restaurant for bread food. Suggest a fancy name for this.'"},"metadata":{}}],"execution_count":61},{"cell_type":"markdown","source":"- This is like a f string, so why don't we just use that?","metadata":{}},{"cell_type":"code","source":"from langchain.chains import LLMChain\n\nchain = LLMChain(llm=llm, prompt=name_template)\nchain.run(\"bread\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T03:54:11.167153Z","iopub.execute_input":"2025-01-20T03:54:11.167558Z","iopub.status.idle":"2025-01-20T03:54:11.650029Z","shell.execute_reply.started":"2025-01-20T03:54:11.167530Z","shell.execute_reply":"2025-01-20T03:54:11.648709Z"}},"outputs":[{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"'\\n\\n\"Bread & Beyond\"'"},"metadata":{}}],"execution_count":65},{"cell_type":"markdown","source":"## Sequential Chain","metadata":{}},{"cell_type":"code","source":"from langchain.prompts import PromptTemplate\nfrom langchain.chains import LLMChain\n\nname_template = PromptTemplate(\n    input_variables = ['cuisine'],\n    template = 'I want to open a restaurant for {cuisine} food. Suggest a fancy name for this.'\n)\n\nname_chain = LLMChain(\n    llm = OpenAI(temperature=0.7),\n    prompt = name_template,\n    output_key = 'restaurant_name'\n)\n\n\nitem_template = PromptTemplate(\n    input_variables = ['restaurant_name'],\n    template = \"Suggest some menu items from {restaurant_name}. Only a list of item names.\"\n)\n\nitem_chain = LLMChain(\n    llm = OpenAI(temperature=0.8),\n    prompt = item_template,\n    output_key = 'menu_items'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T05:39:26.685382Z","iopub.execute_input":"2025-01-20T05:39:26.685735Z","iopub.status.idle":"2025-01-20T05:39:26.935294Z","shell.execute_reply.started":"2025-01-20T05:39:26.685709Z","shell.execute_reply":"2025-01-20T05:39:26.934287Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"from langchain.chains import SequentialChain\n\nchain = SequentialChain(\n    chains = [name_chain, item_chain],\n    input_variables = ['cuisine'],\n    output_variables = ['restaurant_name', 'menu_items']\n)\n\nchain({'cuisine':'bread'})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T05:39:28.385593Z","iopub.execute_input":"2025-01-20T05:39:28.385998Z","iopub.status.idle":"2025-01-20T05:39:30.761594Z","shell.execute_reply.started":"2025-01-20T05:39:28.385965Z","shell.execute_reply":"2025-01-20T05:39:30.760526Z"}},"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"{'cuisine': 'bread',\n 'restaurant_name': '\\n\\n\"Crust & Co.\" ',\n 'menu_items': '\\n1. Margherita Pizza\\n2. Pepperoni Pizza\\n3. Mushroom and Truffle Oil Pizza\\n4. Classic Caesar Salad\\n5. Caprese Salad\\n6. Chicken Pesto Panini\\n7. Meatball Sub\\n8. Tuscan Chicken Alfredo\\n9. Baked Ziti\\n10. Beef Lasagna\\n11. Spinach and Feta Calzone\\n12. Garlic Knots\\n13. Antipasto Platter\\n14. Prosciutto and Arugula Flatbread\\n15. Grilled Vegetable Panini\\n16. Roasted Garlic and Parmesan Breadsticks\\n17. Chicken Parmesan Sandwich\\n18. Shrimp Scampi Linguine\\n19. Eggplant Parmesan\\n20. Tiramisu Cheesecake.'}"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Making an App using Streamlit\n\n- powerful library for building proof of concept apps\n\n```python\nimport streamlit as st\nfrom langchain_helper import generate\n\nst.title(\"Restaurant Name Generator\")\n\ncuisine = st.sidebar.selectbox(\"Pick a cuisine\", (\"Italian\", \"Chinese\", \"French\", \"Spanish\", \"Greek\", \"Indian\", \"Japanese\", \"Korean\", \"Mexican\", \"Thai\"))\n\n# def generate(cusine):\n#     return chain({'cuisine': cusine})\n\nif cuisine:\n    response = generate(cuisine)\n\n    st.header(response['restaurant_name'].replace('\"', ''))\n    menu_items = response['menu_items'].split(',')\n    st.write('**Menu Items:**')\n    for item in menu_items:\n        st.write(item.strip())\n```\n\n- run this locally","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install wikipedia","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T05:13:19.400925Z","iopub.execute_input":"2025-01-20T05:13:19.401415Z","iopub.status.idle":"2025-01-20T05:13:26.251066Z","shell.execute_reply.started":"2025-01-20T05:13:19.401379Z","shell.execute_reply":"2025-01-20T05:13:26.249596Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting wikipedia\n  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.12.3)\nRequirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (2.32.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.12.14)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.6)\nBuilding wheels for collected packages: wikipedia\n  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11679 sha256=6a295c9762fd423ba53b33511d1e91b132b4ecebdd68a1f23b2a2e38134d0de8\n  Stored in directory: /root/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\nSuccessfully built wikipedia\nInstalling collected packages: wikipedia\nSuccessfully installed wikipedia-1.4.0\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"## Langchain Agents","metadata":{}},{"cell_type":"code","source":"from langchain.agents import AgentType, initialize_agent, load_tools\n\nllm = OpenAI(temperature=0.7)\n\ntools = load_tools(\n    ['wikipedia', 'llm-math'],\n    llm = llm,\n)\n\nagent = initialize_agent(\n    tools,\n    llm,\n    agent = AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n    verbose = True # can be used in most langchain functions to list steps\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T05:16:19.168136Z","iopub.execute_input":"2025-01-20T05:16:19.168496Z","iopub.status.idle":"2025-01-20T05:16:19.298757Z","shell.execute_reply.started":"2025-01-20T05:16:19.168472Z","shell.execute_reply":"2025-01-20T05:16:19.297632Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"agent.run('When and where was bread first made?')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T05:16:21.526407Z","iopub.execute_input":"2025-01-20T05:16:21.526798Z","iopub.status.idle":"2025-01-20T05:16:26.340009Z","shell.execute_reply.started":"2025-01-20T05:16:21.526765Z","shell.execute_reply":"2025-01-20T05:16:26.338904Z"}},"outputs":[{"name":"stdout","text":"\n\n\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n\u001b[32;1m\u001b[1;3m I should use wikipedia to search for the history of bread\nAction: wikipedia\nAction Input: \"history of bread\"\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3mPage: History of bread\nSummary: Bread was central to the formation of early human societies. From the Fertile Crescent, where wheat was domesticated, cultivation spread north and west, to Europe and North Africa, and east toward East Asia. This in turn led to the formation of towns, which curtailed nomadic lifestyles, and gave rise to other forms of societal organization. Similar developments occurred in the Americas with maize and in Asia with rice.\n\n\n\nPage: Bread\nSummary: Bread is a staple food prepared from a dough of flour (usually wheat) and water, usually by baking. Throughout recorded history and around the world, it has been an important part of many cultures' diet. It is one of the oldest human-made foods, having been of significance since the dawn of agriculture, and plays an essential role in both religious rituals and secular culture.\nBread may be leavened by naturally occurring microbes (e.g. sourdough), chemicals (e.g. baking soda), industrially produced yeast, or high-pressure aeration, which creates the gas bubbles that fluff up bread. In many countries, commercial bread often contains additives to improve flavor, texture, color, shelf life, nutrition, and ease of production.\n\n\n\nPage: History of bread in California\nSummary: The history of California bread as a prominent factor in the field of bread baking dates from the days of the California Gold Rush around 1849, encompassing the development of sourdough bread in San Francisco. It includes the rise of artisan bakeries in the 1980s, which strongly influenced what has been called the \"Bread Revolution\".\u001b[0m\nThought:\u001b[32;1m\u001b[1;3m I now know the history of bread and where it was first made\nFinal Answer: Bread was first made in the Fertile Crescent, specifically in the region of Mesopotamia, around 8000 BC.\u001b[0m\n\n\u001b[1m> Finished chain.\u001b[0m\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"'Bread was first made in the Fertile Crescent, specifically in the region of Mesopotamia, around 8000 BC.'"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"agent.run('''What is the population of the united states in 2024?\nHow much would it cost to give each person in the US 1 loaf of bread, if that costs $3.61''')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T05:19:44.374750Z","iopub.execute_input":"2025-01-20T05:19:44.375246Z","iopub.status.idle":"2025-01-20T05:19:47.979057Z","shell.execute_reply.started":"2025-01-20T05:19:44.375177Z","shell.execute_reply":"2025-01-20T05:19:47.978008Z"}},"outputs":[{"name":"stdout","text":"\n\n\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n\u001b[32;1m\u001b[1;3m We can use Wikipedia to find the population of the United States in 2024.\nAction: Wikipedia\nAction Input: \"population of united states 2024\"\u001b[0m\nObservation: Wikipedia is not a valid tool, try one of [wikipedia, Calculator].\nThought:\u001b[32;1m\u001b[1;3m We can use the Calculator tool to find the total cost.\nAction: Calculator\nAction Input: 331,002,651 * 3.61\u001b[0m\nObservation: \u001b[33;1m\u001b[1;3mAnswer: 1194919570.11\u001b[0m\nThought:\u001b[32;1m\u001b[1;3m I now know the final answer.\nFinal Answer: It would cost $1,194,919,570.11 to give each person in the US 1 loaf of bread.\u001b[0m\n\n\u001b[1m> Finished chain.\u001b[0m\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"'It would cost $1,194,919,570.11 to give each person in the US 1 loaf of bread.'"},"metadata":{}}],"execution_count":16},{"cell_type":"markdown","source":"## DuckDuckGo Search Agent\n\n- free API","metadata":{}},{"cell_type":"code","source":"!pip install -qU duckduckgo-search langchain-community","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T05:26:52.859644Z","iopub.execute_input":"2025-01-20T05:26:52.860049Z","iopub.status.idle":"2025-01-20T05:26:58.173028Z","shell.execute_reply.started":"2025-01-20T05:26:52.860014Z","shell.execute_reply":"2025-01-20T05:26:58.171428Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"from langchain_community.tools import DuckDuckGoSearchRun\n\nsearch = DuckDuckGoSearchRun()\n\nsearch.invoke(\"Obama's last name?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T05:27:11.548882Z","iopub.execute_input":"2025-01-20T05:27:11.549317Z","iopub.status.idle":"2025-01-20T05:27:12.712247Z","shell.execute_reply.started":"2025-01-20T05:27:11.549278Z","shell.execute_reply":"2025-01-20T05:27:12.710996Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"'Barack Obama is opening up about Malia Obama\\'s decision to drop their family name in her professional life — and how his daughters feel about remaining in the spotlight as they grow older Malia Obama is voting for a fresh start.. As her Hollywood career takes off, Barack and Michelle Obama\\'s oldest daughter has dropped her last name in favor of her middle name, officially going by ... During an appearance on \"The Pivot Podcast,\" former President Barack Obama revealed that his now 26-year-old eldest daughter used a different surname in the credits of her short film \"The ... Former President Barack Obama recently opened up about his eldest daughter\\'s decision to drop her famous last name in a professional setting. Keen to carve her own path and not rest on the high-powered Obama name, Malia has chosen to go by Malia Ann, her first name and middle name, for her newest film project, The Heart. \"Fans did a ...'"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tools = load_tools(\n    ['wikipedia', 'llm-math'],\n    llm=llm,\n)\n\ntools.append(search)\n\nagent = initialize_agent(\n    tools,\n    llm,\n    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n    verbose=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T05:32:13.424021Z","iopub.execute_input":"2025-01-20T05:32:13.424420Z","iopub.status.idle":"2025-01-20T05:32:13.433059Z","shell.execute_reply.started":"2025-01-20T05:32:13.424380Z","shell.execute_reply":"2025-01-20T05:32:13.431855Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"agent.run(\"Who won the Nobel Peace Prize in 2024?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T05:33:41.925238Z","iopub.execute_input":"2025-01-20T05:33:41.925633Z","iopub.status.idle":"2025-01-20T05:33:44.201471Z","shell.execute_reply.started":"2025-01-20T05:33:41.925602Z","shell.execute_reply":"2025-01-20T05:33:44.200356Z"}},"outputs":[{"name":"stdout","text":"\n\n\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n\u001b[32;1m\u001b[1;3m This is a question about current events, so I should use duckduckgo_search to find the answer.\nAction: duckduckgo_search\nAction Input: \"Nobel Peace Prize 2024\"\u001b[0m\nObservation: \u001b[38;5;200m\u001b[1;3mThe Norwegian Nobel Committee has decided to award the Nobel Peace Prize for 2024 to the Japanese organisation Nihon Hidankyo. This grassroots movement of atomic bomb survivors from Hiroshima and Nagasaki, also known as Hibakusha, is receiving the Peace Prize for its efforts to achieve a world free of nuclear weapons and for demonstrating ... The 2024 Nobel Peace Prize has been awarded to Nihon Hidankyo, a grassroots Japanese organization of atomic bomb survivors from Hiroshima and Nagasaki for its efforts \"to achieve a world free of ... The Japanese grassroots group Nihon Hidankyo, an organization of World War II atomic bombing survivors, has won the 2024 Nobel Peace Prize for its efforts to create a world free of nuclear weapons. Nihon Hidankyo, a Japanese group of atomic bomb survivors, has won the 2024 Nobel Peace Prize. Known as hibakusha, the survivors of the 1945 bombings of Hiroshima and Nagasaki have been recognised ... The Nobel Peace Prize, worth 11 million Swedish crowns, or about $1 million, is due to be presented in Oslo on Dec. 10, the anniversary of the death of Swedish industrialist Alfred Nobel, who ...\u001b[0m\nThought:\u001b[32;1m\u001b[1;3m I now know the final answer.\nFinal Answer: The winner of the Nobel Peace Prize in 2024 was Nihon Hidankyo, a Japanese organization of atomic bomb survivors.\u001b[0m\n\n\u001b[1m> Finished chain.\u001b[0m\n","output_type":"stream"},{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"'The winner of the Nobel Peace Prize in 2024 was Nihon Hidankyo, a Japanese organization of atomic bomb survivors.'"},"metadata":{}}],"execution_count":32},{"cell_type":"markdown","source":"## Memory","metadata":{}},{"cell_type":"code","source":"chain.memory  # This is None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T05:40:26.692837Z","iopub.execute_input":"2025-01-20T05:40:26.693260Z","iopub.status.idle":"2025-01-20T05:40:26.697934Z","shell.execute_reply.started":"2025-01-20T05:40:26.693227Z","shell.execute_reply":"2025-01-20T05:40:26.696557Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"from langchain.memory import ConversationBufferMemory\n\nmemory = ConversationBufferMemory()\n\nname_template = PromptTemplate(\n    input_variables = ['cuisine'],\n    template = 'I want to open a restaurant for {cuisine} food. Suggest a fancy name for this.'\n)\n\nname_chain = LLMChain(\n    llm = OpenAI(temperature=0.7),\n    prompt = name_template,\n    output_key = 'restaurant_name',\n    memory = memory,\n)\n\nname_chain.memory","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T06:03:17.965947Z","iopub.execute_input":"2025-01-20T06:03:17.966338Z","iopub.status.idle":"2025-01-20T06:03:18.093945Z","shell.execute_reply.started":"2025-01-20T06:03:17.966308Z","shell.execute_reply":"2025-01-20T06:03:18.092762Z"}},"outputs":[{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"ConversationBufferMemory(chat_memory=InMemoryChatMessageHistory(messages=[]))"},"metadata":{}}],"execution_count":64},{"cell_type":"code","source":"result = name_chain({'cuisine':'bread'})\nname_chain.memory","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T06:03:23.570281Z","iopub.execute_input":"2025-01-20T06:03:23.570647Z","iopub.status.idle":"2025-01-20T06:03:24.020067Z","shell.execute_reply.started":"2025-01-20T06:03:23.570618Z","shell.execute_reply":"2025-01-20T06:03:24.018926Z"}},"outputs":[{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"ConversationBufferMemory(chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='bread', additional_kwargs={}, response_metadata={}), AIMessage(content='\\n\\n\"Bread & Beyond: A Gourmet Bread Experience\"', additional_kwargs={}, response_metadata={})]))"},"metadata":{}}],"execution_count":65},{"cell_type":"markdown","source":"## Memory Buffer Window\n- This memory buffer keeps growing\n- So restrict the buffer size","metadata":{}},{"cell_type":"code","source":"from langchain.chains import ConversationChain\n\nconvo = ConversationChain(llm=llm)\nprint(convo.prompt.template)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T06:06:16.564507Z","iopub.execute_input":"2025-01-20T06:06:16.564916Z","iopub.status.idle":"2025-01-20T06:06:16.571081Z","shell.execute_reply.started":"2025-01-20T06:06:16.564881Z","shell.execute_reply":"2025-01-20T06:06:16.569985Z"}},"outputs":[{"name":"stdout","text":"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n\nCurrent conversation:\n{history}\nHuman: {input}\nAI:\n","output_type":"stream"}],"execution_count":69},{"cell_type":"code","source":"convo.run(\"Who is the youngest chess grandmaster?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T06:07:19.099378Z","iopub.execute_input":"2025-01-20T06:07:19.099784Z","iopub.status.idle":"2025-01-20T06:07:19.925902Z","shell.execute_reply.started":"2025-01-20T06:07:19.099756Z","shell.execute_reply":"2025-01-20T06:07:19.924753Z"}},"outputs":[{"execution_count":70,"output_type":"execute_result","data":{"text/plain":"' The youngest chess grandmaster is Abhimanyu Mishra, who achieved the title at the age of 12 years, 4 months, and 25 days. He is from the United States and became a grandmaster on July 1, 2021.\\n'"},"metadata":{}}],"execution_count":70},{"cell_type":"code","source":"print(convo.memory)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T06:08:01.063697Z","iopub.execute_input":"2025-01-20T06:08:01.064109Z","iopub.status.idle":"2025-01-20T06:08:01.069942Z","shell.execute_reply.started":"2025-01-20T06:08:01.064079Z","shell.execute_reply":"2025-01-20T06:08:01.068623Z"}},"outputs":[{"name":"stdout","text":"chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='Who is the youngest chess grandmaster?', additional_kwargs={}, response_metadata={}), AIMessage(content=' The youngest chess grandmaster is Abhimanyu Mishra, who achieved the title at the age of 12 years, 4 months, and 25 days. He is from the United States and became a grandmaster on July 1, 2021.\\n', additional_kwargs={}, response_metadata={})])\n","output_type":"stream"}],"execution_count":72},{"cell_type":"code","source":"convo.run(\"How old are they, as of 2024?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T06:08:29.991826Z","iopub.execute_input":"2025-01-20T06:08:29.992213Z","iopub.status.idle":"2025-01-20T06:08:30.581869Z","shell.execute_reply.started":"2025-01-20T06:08:29.992162Z","shell.execute_reply":"2025-01-20T06:08:30.580753Z"}},"outputs":[{"execution_count":73,"output_type":"execute_result","data":{"text/plain":"' As of 2024, Abhimanyu Mishra will be 15 years old.'"},"metadata":{}}],"execution_count":73},{"cell_type":"code","source":"from langchain.memory import ConversationBufferWindowMemory\n\nmemory = ConversationBufferWindowMemory(k=1)\n\nconvo = ConversationChain(\n    llm=llm,\n    memory = memory\n)\n\nconvo.run(\"Who is the youngest chess grandmaster?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T06:14:41.771409Z","iopub.execute_input":"2025-01-20T06:14:41.771757Z","iopub.status.idle":"2025-01-20T06:14:42.960322Z","shell.execute_reply.started":"2025-01-20T06:14:41.771727Z","shell.execute_reply":"2025-01-20T06:14:42.959287Z"}},"outputs":[{"execution_count":82,"output_type":"execute_result","data":{"text/plain":"' The youngest chess grandmaster is Abhimanyu Mishra, who achieved the title at the age of 12 years, 4 months, and 25 days. He is from the United States and was officially awarded the title by FIDE (World Chess Federation) in July 2021. He broke the record of Sergey Karjakin, who became a grandmaster at the age of 12 years and 7 months in 2002. Is there anything else you would like to know?'"},"metadata":{}}],"execution_count":82},{"cell_type":"code","source":"convo.run(\"What is 2+2?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T06:15:08.343559Z","iopub.execute_input":"2025-01-20T06:15:08.344259Z","iopub.status.idle":"2025-01-20T06:15:09.285982Z","shell.execute_reply.started":"2025-01-20T06:15:08.344211Z","shell.execute_reply":"2025-01-20T06:15:09.285068Z"}},"outputs":[{"execution_count":83,"output_type":"execute_result","data":{"text/plain":"'  2+2 is 4. This is a basic mathematical equation that is taught in elementary school. It is also known as addition, where you add two numbers together to get a sum. Is there anything else I can help you with?'"},"metadata":{}}],"execution_count":83},{"cell_type":"code","source":"convo.run(\"How old are they, as of 2024?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T06:15:18.093356Z","iopub.execute_input":"2025-01-20T06:15:18.093690Z","iopub.status.idle":"2025-01-20T06:15:18.915773Z","shell.execute_reply.started":"2025-01-20T06:15:18.093665Z","shell.execute_reply":"2025-01-20T06:15:18.914655Z"}},"outputs":[{"execution_count":84,"output_type":"execute_result","data":{"text/plain":"' I do not have enough information to accurately answer that question. I am an AI and do not have access to personal data such as age. Is there something else you would like to know?'"},"metadata":{}}],"execution_count":84},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}